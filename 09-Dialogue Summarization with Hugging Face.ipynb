{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb251aa-fe72-4632-a0a8-c7900df84f51",
   "metadata": {},
   "source": [
    "# Dialogue Summarization with Hugging Face\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In today's fast-paced world, extracting key information from conversations quickly and accurately is crucial. Whether it's customer service interactions, meeting transcripts, or chat logs, summarizing dialogues can save time and improve productivity.\n",
    "\n",
    "## Objective\n",
    "\n",
    "This project aims to develop a tool that automatically summarizes dialogues using Hugging Face's advanced NLP models. Our goal is to create concise and coherent summaries that capture the essence of the conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c7124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '20'\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a739314-03a5-4cc8-943a-848376d6174b",
   "metadata": {},
   "source": [
    "### Loading and Displaying Samples from `samsum` and `dialogsum` Datasets\n",
    "\n",
    "To work with the `samsum` and `dialogsum` datasets, we can use the Hugging Face `datasets` library. This library provides an easy way to load and preprocess datasets. Below, we'll show how to load these datasets and display a few samples from the `samsum` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eac3e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsum_dataset = load_dataset(\"knkarthick/samsum\")\n",
    "dialogsum_dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "\n",
    "samsum_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3e4676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogsum_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf0392-3fc7-4088-8de8-55e9db453efb",
   "metadata": {},
   "source": [
    "#### Display Samples\n",
    "\n",
    "We define a function `show_samples` that will shuffle the dataset and select a specified number of samples to display. The function prints the dialogue and its corresponding summary for each sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85b330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> dialogue: Lucy: omg did you see JK this morning?\n",
      "Sue: I try to avoid it lol\n",
      "Lucy: you should have seen it it was disgusting\n",
      "Sue: I cant do it anymore i try to listen to the radio in the mornings.. jk makes you think the whole world is full of idiots lol\n",
      "Lucy: you may be right I dont know how some of them can go on there in public for the world to see\n",
      "Sue: I would die if I got a call to go on there lol\n",
      "Sue: could you imagine ha ha \n",
      "Lucy: I would piss myself If I saw you and Andy up there\n",
      "Sue: over my dead body !'\n",
      "'>> summary: Sue doesn't watch JK any more as it's disgusting.'\n",
      "\n",
      "'>> dialogue: Wendy: What's up?\n",
      "Simon: Nothing much. I'm painting my cupboards. \n",
      "Angela: Cool what colour?\n",
      "Simon: Green.\n",
      "Ben: I'm just chilling in the garden. \n",
      "Angela: Nice weekend! I'm about to meet Chris.\n",
      "Wendy: Say hello from me!\n",
      "Angela: Will do! And how is your weekend, Wendy?\n",
      "Wendy: Very lazy... The week was hard at work, I really needed some rest. \n",
      "Ben: We should all come and visit Simon in his new apartment!\n",
      "Simon: You are welcome, guys! Whenever you wish.\n",
      "Ben: I should be in Bournemouth next week. \n",
      "Simon: I'm not going anywhere :-)\n",
      "Ben: Cool, I'll call you next week. '\n",
      "'>> summary: This weekend Wendy is very lazy because she worked hard at work, and Angela is meeting Chris. Simon is chilling in the garden and painting his cupboards green. Next week, Ben, Angela, Chris and Wendy will visit him in his new apartament.'\n",
      "\n",
      "'>> dialogue: Petra: Hi Zack, I see you called. Sorry I can't pick up. In lectures all day.\n",
      "Zack: Ok, when will the break be I can try then.\n",
      "Petra: I will call you back in the lunch break because I am not sure if this lecturer will stick closely to the break times in the programme.\n",
      "Zack: OK. \n",
      "Petra: Or you can write to me what it's about. I can type  and read I just can't listen or talk.'\n",
      "'>> summary: Zack called Petra, but she didn't answer because is in lectures all day. Petra will call Zack back during the break. Zack can write to Petra because she can read and write during the lecture. Petra can't talk or listen during the lecture. '\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> dialogue: {example['dialogue']}'\")\n",
    "        print(f\"'>> summary: {example['summary']}'\")\n",
    "\n",
    "\n",
    "show_samples(samsum_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539662a1-3968-42fa-a822-5d7fb098503e",
   "metadata": {},
   "source": [
    "### Cleaning Datasets\n",
    "\n",
    "#### Define the `clean_dataset` function\n",
    "This function filters out entries with summaries that are too short, or where either the summary or dialogue is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2570bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    dataset = dataset.filter(lambda x: len(x[\"summary\"].split()) > 2)\n",
    "    dataset = dataset.filter(lambda x: x[\"summary\"] is not None)\n",
    "    dataset = dataset.filter(lambda x: x[\"dialogue\"] is not None)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e68e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsum_dataset = clean_dataset(samsum_dataset)\n",
    "dialogsum_dataset = clean_dataset(dialogsum_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee59140-1ed3-4403-8c19-516e19dd95c4",
   "metadata": {},
   "source": [
    "#### Merging Datasets\n",
    "\n",
    "Use the `concatenate_datasets` function to merge the cleaned datasets and store them in a new `DatasetDict` called `english_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038f09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> dialogue: #Person1#: So Peter, do you have a favorite comedy?\n",
      "#Person2#: Well, that's hard to say because there are so many good ones. I don't think I could pick a favorite.\n",
      "#Person1#: You know what comedy I really like? ' Ace Ventura, Pet Detective. ' I think Jim Carry is really funny.\n",
      "#Person2#: Oh yeah, that's one of my favorite flicks. I think Jim Carry is one of the funniest comedians ever.\n",
      "#Person1#: I agree. But even though I like comedies, I usually prefer more serious films. My favorite movie is ' Titanic. ''\n",
      "'>> summary: Peter and #Person1# talk about their favourite comedies. They both like the comedian Jim Carry.'\n",
      "\n",
      "'>> dialogue: Hal: Xmas is coming\n",
      "Daphne: and ...\n",
      "Hal: and I'd like to know what you would like to get this year\n",
      "Daphne: surely not the Chinese crap you gave me last year\n",
      "Hal: thought it was funny\n",
      "Daphne: ridiculous rather. give me three days to think ok?\n",
      "Hal: OK, otherwise I'll have to come up with sth and u know I'm not that good at it\n",
      "Daphne: you bet'\n",
      "'>> summary: Hal wants to know which present Daphne would like for Xmas, as last year she didn't appreciate Hal's gift.'\n",
      "\n",
      "'>> dialogue: Debra: I spilled some wine on the ceiling \n",
      "Debra: Any idea how to remove the stains??\n",
      "Heather: How did you do that???\n",
      "Debra: Don’t ask :D\n",
      "Debra: I need to get rid of the stains otherwise they will take my deposit\n",
      "Heather: I guess you’ll need to paint it\n",
      "Heather: White paint is easy to get. Buy the smallest can.'\n",
      "'>> summary: Debra stained the ceiling with wine. She has to remove the stains in order not to lose a deposit. '\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "english_dataset = DatasetDict()\n",
    "\n",
    "for split in samsum_dataset.keys():\n",
    "    english_dataset[split] = concatenate_datasets(\n",
    "        [samsum_dataset[split], dialogsum_dataset[split]]\n",
    "    )\n",
    "    english_dataset[split] = english_dataset[split].shuffle(seed=42)\n",
    "\n",
    "# Peek at a few examples\n",
    "show_samples(english_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f246445-48be-43d3-9911-895e539e7858",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcc63f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_3045</td>\n",
       "      <td>#Person1#: Now I know why I split up with Mike...</td>\n",
       "      <td>#Person1# thinks she broke up with Mike becaus...</td>\n",
       "      <td>astrology and fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13821145</td>\n",
       "      <td>Tommy: dudes, I have an idea for a larp.\\nAidy...</td>\n",
       "      <td>Tommy has an idea for a new larp. It's about w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13731110</td>\n",
       "      <td>George: Hey, let me know when you can make it ...</td>\n",
       "      <td>George and Alex are going to meet on Tuesday a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13810213</td>\n",
       "      <td>Sophie: Hi my dear. A very happy birthday to y...</td>\n",
       "      <td>Sophie is wishing Mel a happy birthday. Mel is...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4656</td>\n",
       "      <td>#Person1#: Bill, do you know when did the Chin...</td>\n",
       "      <td>#Person1# and Bill are talking about Teachers'...</td>\n",
       "      <td>Teachers' Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27182</th>\n",
       "      <td>13729504</td>\n",
       "      <td>Pete: I wonder how Brexit will affect the situ...</td>\n",
       "      <td>Pete and Jake are worried about Brexit and Pol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27183</th>\n",
       "      <td>13728042</td>\n",
       "      <td>Adam: need a drink\\nAdam: wanna go to Paddys?\\...</td>\n",
       "      <td>Adam and Will are going to Paddys at 7.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27184</th>\n",
       "      <td>13681133</td>\n",
       "      <td>Matthew: How was your trip to Italy?\\nKim: It ...</td>\n",
       "      <td>Kim has been to Sicily in Italy. She visited t...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27185</th>\n",
       "      <td>train_7386</td>\n",
       "      <td>#Person1#: Excuse me, sir, can you help me? I ...</td>\n",
       "      <td>#Person1# needs to buy a bed that isn't too bi...</td>\n",
       "      <td>buy a bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27186</th>\n",
       "      <td>13729111</td>\n",
       "      <td>Darcy: This new Ruth Wilson show looks good!\\n...</td>\n",
       "      <td>There is a new show with Ruth Wilson. She play...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27187 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                           dialogue  \\\n",
       "0      train_3045  #Person1#: Now I know why I split up with Mike...   \n",
       "1        13821145  Tommy: dudes, I have an idea for a larp.\\nAidy...   \n",
       "2        13731110  George: Hey, let me know when you can make it ...   \n",
       "3        13810213  Sophie: Hi my dear. A very happy birthday to y...   \n",
       "4      train_4656  #Person1#: Bill, do you know when did the Chin...   \n",
       "...           ...                                                ...   \n",
       "27182    13729504  Pete: I wonder how Brexit will affect the situ...   \n",
       "27183    13728042  Adam: need a drink\\nAdam: wanna go to Paddys?\\...   \n",
       "27184    13681133  Matthew: How was your trip to Italy?\\nKim: It ...   \n",
       "27185  train_7386  #Person1#: Excuse me, sir, can you help me? I ...   \n",
       "27186    13729111  Darcy: This new Ruth Wilson show looks good!\\n...   \n",
       "\n",
       "                                                 summary               topic  \n",
       "0      #Person1# thinks she broke up with Mike becaus...  astrology and fact  \n",
       "1      Tommy has an idea for a new larp. It's about w...                None  \n",
       "2      George and Alex are going to meet on Tuesday a...                None  \n",
       "3      Sophie is wishing Mel a happy birthday. Mel is...                None  \n",
       "4      #Person1# and Bill are talking about Teachers'...       Teachers' Day  \n",
       "...                                                  ...                 ...  \n",
       "27182  Pete and Jake are worried about Brexit and Pol...                None  \n",
       "27183            Adam and Will are going to Paddys at 7.                None  \n",
       "27184  Kim has been to Sicily in Italy. She visited t...                None  \n",
       "27185  #Person1# needs to buy a bed that isn't too bi...           buy a bed  \n",
       "27186  There is a new show with Ruth Wilson. She play...                None  \n",
       "\n",
       "[27187 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset.set_format(\"pandas\")\n",
    "train_df = english_dataset[\"train\"][:]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fb889-7c6a-440d-ba70-b070868fc716",
   "metadata": {},
   "source": [
    "### Analyzing Dialogues and Summary Lengths\n",
    "\n",
    "This analysis helps in understanding the distribution and range of word lengths in both dialogues and summaries, which is essential for tasks such as text summarization, where optimal summary length is a consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553da6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in train_df['dialogue']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in train_df['summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42ee15-e94d-41ad-8947-c9ee8999470c",
   "metadata": {},
   "source": [
    "**From the plot analysis:**\n",
    "\n",
    "- **Input Length (`max_input_length`)**: Dialogues typically peak around 350 words, suggesting `max_input_length = 350` captures the majority of dialogues adequately without significant truncation.\n",
    "\n",
    "- **Target Length (`max_target_length`)**: Summaries tend to center around 50 words, making `max_target_length = 50` suitable for generating concise and informative summaries aligned with the original dialogues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e82df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 350\n",
    "max_target_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8d12b-715e-4f28-83c2-13d4c765d778",
   "metadata": {},
   "source": [
    "### Removing Columns from `english_dataset`\n",
    "\n",
    "The code snippet below removes the 'id' and 'topic' columns from `english_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e34ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dialogue', 'summary'],\n",
       "        num_rows: 27187\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['dialogue', 'summary'],\n",
       "        num_rows: 1318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dialogue', 'summary'],\n",
       "        num_rows: 2319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = english_dataset.remove_columns(['id'])\n",
    "english_dataset = english_dataset.remove_columns(['topic'])\n",
    "\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46010705-8e3f-4678-b238-0751f220dbb6",
   "metadata": {},
   "source": [
    "### Tokenizing Text Data with Transformers\n",
    "\n",
    "  - Here, `\"t5-small\"` is chosen as the model checkpoint, indicating a smaller version of the T5 model.\n",
    "  - The `AutoTokenizer.from_pretrained` method loads and caches the tokenizer associated with the specified model checkpoint.\n",
    "  - This tokenizer can then be used to convert text into a format suitable for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a303031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23eebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [27, 1858, 1036, 81, 5879, 6630, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I loved learning about Machine Learning!\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7110c722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁I', '▁loved', '▁learning', '▁about', '▁Machine', '▁Learning', '!', '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d321e7a-b1a7-4894-a06a-1e604a599439",
   "metadata": {},
   "source": [
    "### Text Preprocessing with Tokenization\n",
    "\n",
    "This code snippet demonstrates text preprocessing using a tokenizer:\n",
    "\n",
    "1. **Dataset Formatting**:\n",
    "   It resets `english_dataset` to its original format.\n",
    "\n",
    "2. **Preprocessing Function**:\n",
    "   - **Purpose**: Tokenizes dialogues and summaries with `tokenizer`, ensuring sequences adhere to specified maximum lengths (`max_input_length` for dialogues and `max_target_length` for summaries).\n",
    "   - **Key Step**: `model_inputs[\"labels\"] = labels[\"input_ids\"]` prepares data for sequence-to-sequence models, crucial for tasks like text summarization.\n",
    "\n",
    "### Sequence-to-Sequence Models\n",
    "\n",
    "In sequence-to-sequence models:\n",
    "\n",
    "- **Input Sequence**: Text input (e.g., dialogue).\n",
    "- **Output Sequence**: Text to generate (e.g., summary).\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Using a `tokenizer`, text converts to token IDs:\n",
    "\n",
    "1. **Dialogue Tokenization**: Converts dialogue to tokens in `model_inputs`.\n",
    "2. **Summary Tokenization**: Converts summary to tokens in `labels`.\n",
    "\n",
    "### Model Inputs and Labels\n",
    "\n",
    "- **Model Inputs**: Tokenized dialogue for model input.\n",
    "- **Labels**: Tokenized summary for model target during training.\n",
    "\n",
    "This preprocesses text for models, enhancing training and prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17057a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d14f5481144fada4eefb094d572531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "english_dataset.reset_format()\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"dialogue\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"summary\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_datasets = english_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70acac-08c1-40d8-af08-0b9c2ac9defc",
   "metadata": {},
   "source": [
    "### Baseline Summary Generation\n",
    "\n",
    "The `three_sentence_summary` function utilizes NLTK's `sent_tokenize` to extract the initial three sentences from a text, establishing a basic baseline for summarization. This method ensures accurate segmentation, accommodating complex cases like acronyms (\"U.S.\", \"U.N.\").\n",
    "\n",
    "This approach is foundational in summarization tasks, offering a straightforward yet effective method to condense text into a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab5cdfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/negar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1ea4c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tommy: dudes, I have an idea for a larp.\n",
      "Aidy: go on\n",
      "Connor: let's hear it.\n",
      "Tommy: It would be about witches a'la new Sabrina, a coven meeting, modern style, but with a victorian twist\n",
      "Sarah: sounds cute\n",
      "Tommy: you wanna know the twist?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "\n",
    "print(three_sentence_summary(english_dataset['train'][1][\"dialogue\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465f2b3-88cc-4f50-aa44-3429a58f953d",
   "metadata": {},
   "source": [
    "### Evaluating Summarization with ROUGE Score\n",
    "\n",
    "#### ROUGE Score\n",
    "\n",
    "The ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score is a metric commonly used to assess the quality of text summarization. It measures the overlap and similarity between a generated summary and one or more reference summaries.\n",
    "\n",
    "   - **Purpose**: The `evaluate_baseline` function generates summaries (`summaries`) using `three_sentence_summary` for each dialogue in `dataset[\"dialogue\"]`. It then computes the ROUGE score (`metric.compute`) by comparing these generated summaries (`predictions`) against human-written reference summaries (`references`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f9a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rouge_score\n",
    "# pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e026b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f20000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"dialogue\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dcdefa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 28.69, 'rouge2': 8.54, 'rougeL': 22.56, 'rougeLsum': 25.86}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_baseline(english_dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfead4-a1e1-4799-8283-7e88db8e03b1",
   "metadata": {},
   "source": [
    "### Fine-tuning T5 with the Trainer API\n",
    "\n",
    "1. **Loading the Pretrained Model**:\n",
    "\n",
    "   - **Model Initialization**: Loads the pre-trained T5 model from the `t5-small` checkpoint using `AutoModelForSeq2SeqLM`. This class is designed for sequence-to-sequence tasks, such as summarization, and will automatically download and cache the model weights.\n",
    "\n",
    "2. **Data Collation for Training**:\n",
    "   - **Purpose**: For encoder-decoder models like T5, it's important to shift the labels to the right by one during decoding. This ensures the decoder only sees the previous ground truth labels, preventing it from memorizing current or future labels.\n",
    "   - **Solution**: The `DataCollatorForSeq2Seq` dynamically pads inputs and labels, handling the label shifting automatically.\n",
    "   - **Data Collator**: Prepares the data collator to handle tokenization, padding, and batching for training. This ensures that inputs and labels are correctly formatted for the model.\n",
    "\n",
    "These steps set up the model and data pipeline for fine-tuning T5 on summarization tasks. Using the `Trainer` API simplifies the training process by managing the training loop, evaluation, and other necessary tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "789efc62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T20:23:58.445317Z",
     "iopub.status.busy": "2024-07-16T20:23:58.444948Z",
     "iopub.status.idle": "2024-07-16T20:24:00.140421Z",
     "shell.execute_reply": "2024-07-16T20:24:00.139444Z",
     "shell.execute_reply.started": "2024-07-16T20:23:58.445281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dc5a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e3f56-15d9-43a5-a413-5f7a1304924e",
   "metadata": {},
   "source": [
    "3. **Removing String Columns**:\n",
    "   - **Reason**: Removes columns with string data from the tokenized datasets. This step ensures that the data collator only processes columns it can pad, such as token IDs, attention masks, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "589ba030",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    english_dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6b5375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 27187\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce4072-7219-48f3-a1ff-2288cb334672",
   "metadata": {},
   "source": [
    "4. **Formatting Data for the Data Collator**:\n",
    "   - **Reason**: The data collator expects a list of dictionaries, each representing a single example in the dataset. We need to format the data into this expected structure before passing it to the data collator.\n",
    "\n",
    "   - **Data Wrangling**: Prepares a list of examples (`features`) from the tokenized training dataset and passes it to the data collator. This ensures the data is correctly padded and ready for model training.\n",
    "  \n",
    "3. **Observing Data Collation Effects**:\n",
    "   - **Padding**: The first example might be longer than the second, so the `input_ids` and `attention_mask` of the second example are padded on the right with a `[PAD]` token (ID 0).\n",
    "   - **Labels Padding**: Labels are padded with `-100` to ensure that padding tokens are ignored by the loss function.\n",
    "   - **Decoder Input IDs**: A new `decoder_input_ids` is created by shifting the labels to the right, inserting a `[PAD]` token at the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f539f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 350), dtype=int32, numpy=\n",
       "array([[ 1713,   345, 13515,   536,  4663,    10,   852,    27,   214,\n",
       "          572,    27,  5679,    95,    28,  4794,     5,   101,   435,\n",
       "           62,   130,   914,    59,   207,    21,   284,   119,     5,\n",
       "         1713,   345, 13515,   357,  4663,    10,    86,   125,  1155,\n",
       "           58,  1713,   345, 13515,   536,  4663,    10,  1548,     6,\n",
       "            3,    88,    19,     3,     9,  4541,   180,  5356,  5310,\n",
       "          302,  4024,     6,   298,    27,   183,     3,     9,  9520,\n",
       "            5,   101,    33,    29,    31,    17,   310,  7441,  1713,\n",
       "          345, 13515,   357,  4663,    10,  1626,    18,  1024,     6,\n",
       "           78,    25,   857,    16,     3, 12163,  1863,    58,  1713,\n",
       "          345, 13515,   536,  4663,    10,   363,    31,     7,  6765,\n",
       "           81,    24,    55,   282,     3,     9,   568,  2170,   365,\n",
       "            8,  1320,    13,  9520,     6,    27,   183,   234,    18,\n",
       "         5850,    53,    11,  1663,    21,     3,     9,  9257,   384,\n",
       "          280,     5,   299,  1315,    12,     3, 12163,  1863,     6,\n",
       "          180,  5356,  5310,   302,  3413,    33,   396, 23985,    11,\n",
       "         1020,    18, 14867,     5,   328, 28022,   317,    13,  1374,\n",
       "            3,     9, 10166,    11,  9257,   280,     5,  1713,   345,\n",
       "        13515,   357,  4663,    10,    27,     7,    24,    78,    58,\n",
       "           27,    31,    51,  7403,    34,    19,   396,  5658,    18,\n",
       "        11644,    12,  5191,   151,   338,     3, 12163,  1863,     5,\n",
       "           94,    31,     7,    66, 26524,     7,    55,  1713,   345,\n",
       "        13515,   536,  4663,    10,   299,    16,    82,   495,     6,\n",
       "            8,   685,  6407,     8,  4516,     5,  4794,    19, 28845,\n",
       "            6, 11273,     6,   373,    38,  1434,    38,     3,     9,\n",
       "          836,   159,    63,     6,    68,  1077,   396, 17091,     5,\n",
       "           94,     3,    89,  3535,    35,     7,   140,    55,  1713,\n",
       "          345, 13515,   357,  4663,    10,   299,    38,   623,    38,\n",
       "           27,  1423,     6,    25,   192,  4682,    30,   114,     3,\n",
       "            9,   629,    30,  1472,   116,    25,   166,  1736,     5,\n",
       "         1713,   345, 13515,   536,  4663,    10,     3, 27888,     5,\n",
       "          299,   865,    30,     6,     3,    88,   124,     7,    72,\n",
       "           81,   112,  1415,   145,   333,     5,  3118,  1330,    12,\n",
       "           36,     8,   394,    66,     6,    11,    66,    21,   376,\n",
       "           18,     7,    32,   231,    24,     3,    88,   744,    31,\n",
       "           17,   237,  3542, 13164, 14144,    53,     3,     9,   239,\n",
       "           91,    28,   140,     5,     1,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       [22091,    10,   146,  1395,     6,    27,    43,    46,   800,\n",
       "           21,     3,     9,    50,    52,   102,     5, 12090,    63,\n",
       "           10,   281,    30,     3, 22329,    10,   752,    31,     7,\n",
       "         1616,    34,     5, 22091,    10,    94,   133,    36,    81,\n",
       "        22583,    15,     7,     3,     9,    31,   521,   126, 11315,\n",
       "           52,    77,     9,     6,     3,     9,   576,  1926,  1338,\n",
       "            6,   941,   869,     6,    68,    28,     3,     9,     3,\n",
       "         7287,  3600,   152,  9135,  8077,    10,  2993,  5295, 22091,\n",
       "           10,    25, 14371,     9,   214,     8,  9135,    58, 12090,\n",
       "           63,    10,   830,    34,    30, 22091,    10,   132,    33,\n",
       "          204, 26405,     7,     3,    18,    80,   241,    31,     7,\n",
       "           12,  1350,    81,     8,   647,    13,     8,   576,  1926,\n",
       "           11,    33,  2957,    72,  3095,  1601,  2254,     6,     8,\n",
       "          119,    19,   700,  3536,     3, 27345,    57,    20,  2157,\n",
       "            7,    11,  2746,     8,   119,   985,    12,  1320,     3,\n",
       "            9,     3,  5379,    17,    28,   135,    42,     3,    18,\n",
       "            3,    99,  1327,  1307,   930,     3,    18,  5781,   135,\n",
       "           16,     8,   414,     5,     3, 22329,    10,  7823,     5,\n",
       "         3520,     8,   209,     7,    17, 26405,    43,   136, 23373,\n",
       "           81,   125,    31,     7,   352,    30,    58, 22091,    10,\n",
       "         1404,   151,   103,     6,    68,    34,    31,     7,    59,\n",
       "         2017,   801, 12090,    63,    10,   454,    51,     6,   429,\n",
       "           36,     3,     9,   720,    73,  3849,   663,    26,     3,\n",
       "           18,     8,   209,     7,    17, 26405,   429,    36,  5676,\n",
       "           49,   145,     8,   204,   727,  8077,    10,   125,    81,\n",
       "            3,     9,   220,    52,    26, 26405,    12,  2109,    34,\n",
       "           91,    58, 22091,    10,   114,   125,    58,  8077,    10,\n",
       "           20,  2157, 26366,    16, 31993,    58, 12090,    63,    10,\n",
       "          264,   258,     8,   788,    40,    19,   344,     8,    20,\n",
       "         2157,     7,    11,     8, 26366,    11,     8,   151,    33,\n",
       "          341,   773,     9,  5676, 22091,    10,   328,    31,    60,\n",
       "          341,     3,    51,  2568,    79,    54,   103,     3,     9,\n",
       "          418,     5,     3, 22329,    10,    27,   278,    31,    17,\n",
       "          317,     8,   166, 26405,   133,    36,  5676,     3,    18,\n",
       "           34,    66,  5619,    30,     8, 11754,     7,    13,     8,\n",
       "          467,     5,     3, 22329,    10,     3,    63,    17,  1063,\n",
       "          228,   131,    38,  1153,   143,     8,    20,  2157,     7,\n",
       "         5676,     6,  5619,    30,     8,   408, 22091,    10,   175,\n",
       "           33,   207,   500,    31,     7,   713,     6,     1]],\n",
       "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 350), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=int32)>, 'labels': <tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1713,   345, 13515,   536,  4663,   317,     7,   255,  8238,\n",
       "           95,    28,  4794,   250,    79,    33,    29,    31,    17,\n",
       "         7441,    16,     3, 12163,  1863,     5,  1713,   345, 13515,\n",
       "          357,  4663,   317,     7,     3, 24331,   151,    57,     3,\n",
       "        12163,  1863,    19,  1786,   298,  1713,   345, 13515,   536,\n",
       "         4663,   317,     7,   160,     1],\n",
       "       [22091,    65,    46,   800,    21,     3,     9,   126,    50,\n",
       "           52,   102,     5,    94,    31,     7,    81, 22583,    15,\n",
       "            7,     5,   290,   133,    36,   204, 26405,     7,     6,\n",
       "           80,    13,   135,     3, 27345,    57,    20,  2157,     7,\n",
       "            5,  8077,  6490,  2651,     3,     9,  1025, 26405,    13,\n",
       "           20,  2157, 26366,     5,     1]])>, 'decoder_input_ids': <tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[    0,  1713,   345, 13515,   536,  4663,   317,     7,   255,\n",
       "         8238,    95,    28,  4794,   250,    79,    33,    29,    31,\n",
       "           17,  7441,    16,     3, 12163,  1863,     5,  1713,   345,\n",
       "        13515,   357,  4663,   317,     7,     3, 24331,   151,    57,\n",
       "            3, 12163,  1863,    19,  1786,   298,  1713,   345, 13515,\n",
       "          536,  4663,   317,     7,   160],\n",
       "       [    0, 22091,    65,    46,   800,    21,     3,     9,   126,\n",
       "           50,    52,   102,     5,    94,    31,     7,    81, 22583,\n",
       "           15,     7,     5,   290,   133,    36,   204, 26405,     7,\n",
       "            6,    80,    13,   135,     3, 27345,    57,    20,  2157,\n",
       "            7,     5,  8077,  6490,  2651,     3,     9,  1025, 26405,\n",
       "           13,    20,  2157, 26366,     5]])>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6b55b-59a7-4411-a25b-3cbf7f407353",
   "metadata": {},
   "source": [
    "### Converting Datasets\n",
    "\n",
    "**Convert Training and Evaluation Datasets**:\n",
    "   - **Training Dataset**: The training dataset is prepared using `model.prepare_tf_dataset`, with shuffling enabled and a batch size of 8. This ensures that the training data is fed into the model in a randomized order, which helps improve generalization.\n",
    "   - **Evaluation Dataset**: The evaluation dataset is similarly prepared but without shuffling, ensuring that the evaluation data is fed in a consistent order for accurate assessment of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d85787d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T20:24:01.188239Z",
     "iopub.status.busy": "2024-07-16T20:24:01.187237Z",
     "iopub.status.idle": "2024-07-16T20:24:02.008159Z",
     "shell.execute_reply": "2024-07-16T20:24:02.007184Z",
     "shell.execute_reply.started": "2024-07-16T20:24:01.188207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(16, 350), dtype=int64, numpy=\n",
      "array([[ 1713,   345, 13515, ...,     0,     0,     0],\n",
      "       [ 1713,   345, 13515, ...,     0,     0,     0],\n",
      "       [ 1022,     7,  2452, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 1713,   345, 13515, ...,  1807,    11,     1],\n",
      "       [21412,    10,     3, ...,     0,     0,     0],\n",
      "       [ 1713,   345, 13515, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(16, 350), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>, 'decoder_input_ids': <tf.Tensor: shape=(16, 50), dtype=int64, numpy=\n",
      "array([[    0,  1079,    19, 12744,   250,     3,    88,    19,    29,\n",
      "           31,    17,  2918,    11,   744,    31,    17,   129,   590,\n",
      "          168,    28,   119,  1652,     5,  1713,   345, 13515,   357,\n",
      "         4663,   987,     7,  1079,    12,   317,    13,     3, 19801,\n",
      "          250,    34,    31,     7,   207,    21,   376,    12,   320,\n",
      "           21,   430,   613,     5,     1],\n",
      "       [    0,  1713,   345, 13515,   357,  4663,    19,   479,    21,\n",
      "          128,  6001,     7,    11,   114,     7,     8,    80,  1713,\n",
      "          345, 13515,   357,  4663,  1568,     7,    44,   336,     5,\n",
      "            1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,  1022,     7,  2452,    33,  5088,   174,    12,   609,\n",
      "           16,     3,     9,   516,    57,     8,   414,    13,   416,\n",
      "          471,     5,   328,    31,    60,   321,   182,  3164,     6,\n",
      "           68,  1022,     7,  2452, 10419,     7,    30,  1338,     5,\n",
      "         5088,  3725,  2065,     7,    12,   942,   128,    97,    48,\n",
      "          471,     5,     1,     0,     0],\n",
      "       [    0,  7124,    19,     3, 10475, 29107,    28,   112,  5481,\n",
      "         4544,    84,  8238,   323,   220,   648,    16,     3,     9,\n",
      "          215,     5,  8595,    19,    46,     3, 31133,  1819,     5,\n",
      "            1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,     3,     4,     9,  5144,   817,     7,  1713,   345,\n",
      "        13515,   536,  4663,    81,     8,  2023,    13,  2453,  6979,\n",
      "           11,  1713,   345, 13515,   536,  4663,   987,     7,     8,\n",
      "          194,    12,  1634,    95,     6,    68,     3,     4,     9,\n",
      "         5144,   845,   132,    31,     7,   150,  1160,     5,     1,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0, 18063,    65,   118,    12,     8,  1184,  6520,    15,\n",
      "          152,     3,     9,   360,   648,     5,   438,   160,  1362,\n",
      "          255,    47,    16,  7186, 18089,    11, 11038, 14073,    11,\n",
      "           28,  9316,    16,     8, 19169,   152,  5750,     5,   886,\n",
      "           13,     8,  1184,  6520,    15,   152,  1440,    33,   859,\n",
      "            8,   167,  5107,    16,     8],\n",
      "       [    0,  7826,    19,  2492,     3,     9,  3202,     5, 14404,\n",
      "           51,    23,    19,    29,    31,    17,  3036,    13,   160,\n",
      "            5,  7826,    56,  1492,   192,   767,    16,  1524,     5,\n",
      "            1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0, 21812,   817,     7,   160,  7370,    24,   255, 12191,\n",
      "           12,   752,  6538,  2405,   160,  7270, 11920,     5,  1347,\n",
      "         7370, 11308,     7,   160,     5,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0, 19454,     6,  4320,   152,    11,  2194,  2498,  2065,\n",
      "           12,  1605,     8,   467,    16,     3,     9,  1207,    44,\n",
      "        31842,   180,  1824,     5,    37,  1588,  3511,    44,   505,\n",
      "            3,    32,    31, 17407,     5,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0, 11859,    11,  6538,   877,    12,  3083,    17,  3600,\n",
      "            9,   836,  7291,    32,  4981,    11,  6528,    34,     5,\n",
      "            1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,  2133,    35,  1916,     8,   629,   250,    13,   112,\n",
      "         2512,    11,    19,   352,    12,  1175,  5721,  3742,     5,\n",
      "         2867,  8158,    63,    11,  1713,   345, 13515,   357,  4663,\n",
      "         3041,   376,     5,     1,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,  1713,   345, 13515,   536,  4663,    11,  1713,   345,\n",
      "        13515,   357,  4663,   278,    31,    17,   809,    34,    24,\n",
      "            8,   789,  1217,     8,   569,  1034,  1104,    38,    79,\n",
      "           56,   129,     3,     9,  3718,   691,   116,    79,   129,\n",
      "          625,     5,     1,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,  2737,  6490,   352,    12,     3,     9,   126,  1207,\n",
      "            5,  1713,   345, 13515,   357,  4663,  2065,     7,  3755,\n",
      "          120,     5,     1,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    0,  1713,   345, 13515,   536,  4663,  3088, 13615,   272,\n",
      "         6203,    12,   987,    81,     8,  6543,    21,     8,  4579,\n",
      "           16,   469,    31,     7,  8468,     5, 13615,   817,     7,\n",
      "         1713,   345, 13515,   536,  4663,     8,   616,    11,  2801,\n",
      "           13,     8,  4579,     5,    94,    65,     3,     9,   418,\n",
      "           13,   892,    11,    19, 14610],\n",
      "       [    0, 21412,    19,    16, 28928,     5, 18163,    19,    44,\n",
      "            8,  7868,     5,   216,     3,  8070,    16,     3,     9,\n",
      "         1595,    16,     8,  2050,   298,    16, 28928,     5, 21412,\n",
      "           19,    16,   205,  8419,   159,     5,   451,    11,  4794,\n",
      "            3,   342,  3688,    16,     3,     9, 25552,     5, 18163,\n",
      "           56,   129,     8,  1115,    13],\n",
      "       [    0,  1713,   345, 13515,   536,  4663,    11,  1713,   345,\n",
      "        13515,   357,  4663,    43,    29,    31,    17,   894,   284,\n",
      "          119,    21,   192,   203,     5,  1713,   345, 13515,   357,\n",
      "         4663,  1550,    12,  5213,   496,    44,   837,   254,    12,\n",
      "          669,  1038,  5030,     5,     1,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0]])>}, <tf.Tensor: shape=(16, 50), dtype=int64, numpy=\n",
      "array([[ 1079,    19, 12744,   250,     3,    88,    19,    29,    31,\n",
      "           17,  2918,    11,   744,    31,    17,   129,   590,   168,\n",
      "           28,   119,  1652,     5,  1713,   345, 13515,   357,  4663,\n",
      "          987,     7,  1079,    12,   317,    13,     3, 19801,   250,\n",
      "           34,    31,     7,   207,    21,   376,    12,   320,    21,\n",
      "          430,   613,     5,     1,  -100],\n",
      "       [ 1713,   345, 13515,   357,  4663,    19,   479,    21,   128,\n",
      "         6001,     7,    11,   114,     7,     8,    80,  1713,   345,\n",
      "        13515,   357,  4663,  1568,     7,    44,   336,     5,     1,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [ 1022,     7,  2452,    33,  5088,   174,    12,   609,    16,\n",
      "            3,     9,   516,    57,     8,   414,    13,   416,   471,\n",
      "            5,   328,    31,    60,   321,   182,  3164,     6,    68,\n",
      "         1022,     7,  2452, 10419,     7,    30,  1338,     5,  5088,\n",
      "         3725,  2065,     7,    12,   942,   128,    97,    48,   471,\n",
      "            5,     1,  -100,  -100,  -100],\n",
      "       [ 7124,    19,     3, 10475, 29107,    28,   112,  5481,  4544,\n",
      "           84,  8238,   323,   220,   648,    16,     3,     9,   215,\n",
      "            5,  8595,    19,    46,     3, 31133,  1819,     5,     1,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [    3,     4,     9,  5144,   817,     7,  1713,   345, 13515,\n",
      "          536,  4663,    81,     8,  2023,    13,  2453,  6979,    11,\n",
      "         1713,   345, 13515,   536,  4663,   987,     7,     8,   194,\n",
      "           12,  1634,    95,     6,    68,     3,     4,     9,  5144,\n",
      "          845,   132,    31,     7,   150,  1160,     5,     1,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [18063,    65,   118,    12,     8,  1184,  6520,    15,   152,\n",
      "            3,     9,   360,   648,     5,   438,   160,  1362,   255,\n",
      "           47,    16,  7186, 18089,    11, 11038, 14073,    11,    28,\n",
      "         9316,    16,     8, 19169,   152,  5750,     5,   886,    13,\n",
      "            8,  1184,  6520,    15,   152,  1440,    33,   859,     8,\n",
      "          167,  5107,    16,     8,     1],\n",
      "       [ 7826,    19,  2492,     3,     9,  3202,     5, 14404,    51,\n",
      "           23,    19,    29,    31,    17,  3036,    13,   160,     5,\n",
      "         7826,    56,  1492,   192,   767,    16,  1524,     5,     1,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [21812,   817,     7,   160,  7370,    24,   255, 12191,    12,\n",
      "          752,  6538,  2405,   160,  7270, 11920,     5,  1347,  7370,\n",
      "        11308,     7,   160,     5,     1,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [19454,     6,  4320,   152,    11,  2194,  2498,  2065,    12,\n",
      "         1605,     8,   467,    16,     3,     9,  1207,    44, 31842,\n",
      "          180,  1824,     5,    37,  1588,  3511,    44,   505,     3,\n",
      "           32,    31, 17407,     5,     1,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [11859,    11,  6538,   877,    12,  3083,    17,  3600,     9,\n",
      "          836,  7291,    32,  4981,    11,  6528,    34,     5,     1,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [ 2133,    35,  1916,     8,   629,   250,    13,   112,  2512,\n",
      "           11,    19,   352,    12,  1175,  5721,  3742,     5,  2867,\n",
      "         8158,    63,    11,  1713,   345, 13515,   357,  4663,  3041,\n",
      "          376,     5,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [ 1713,   345, 13515,   536,  4663,    11,  1713,   345, 13515,\n",
      "          357,  4663,   278,    31,    17,   809,    34,    24,     8,\n",
      "          789,  1217,     8,   569,  1034,  1104,    38,    79,    56,\n",
      "          129,     3,     9,  3718,   691,   116,    79,   129,   625,\n",
      "            5,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [ 2737,  6490,   352,    12,     3,     9,   126,  1207,     5,\n",
      "         1713,   345, 13515,   357,  4663,  2065,     7,  3755,   120,\n",
      "            5,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100],\n",
      "       [ 1713,   345, 13515,   536,  4663,  3088, 13615,   272,  6203,\n",
      "           12,   987,    81,     8,  6543,    21,     8,  4579,    16,\n",
      "          469,    31,     7,  8468,     5, 13615,   817,     7,  1713,\n",
      "          345, 13515,   536,  4663,     8,   616,    11,  2801,    13,\n",
      "            8,  4579,     5,    94,    65,     3,     9,   418,    13,\n",
      "          892,    11,    19, 14610,     1],\n",
      "       [21412,    19,    16, 28928,     5, 18163,    19,    44,     8,\n",
      "         7868,     5,   216,     3,  8070,    16,     3,     9,  1595,\n",
      "           16,     8,  2050,   298,    16, 28928,     5, 21412,    19,\n",
      "           16,   205,  8419,   159,     5,   451,    11,  4794,     3,\n",
      "          342,  3688,    16,     3,     9, 25552,     5, 18163,    56,\n",
      "          129,     8,  1115,    13,     1],\n",
      "       [ 1713,   345, 13515,   536,  4663,    11,  1713,   345, 13515,\n",
      "          357,  4663,    43,    29,    31,    17,   894,   284,   119,\n",
      "           21,   192,   203,     5,  1713,   345, 13515,   357,  4663,\n",
      "         1550,    12,  5213,   496,    44,   837,   254,    12,   669,\n",
      "         1038,  5030,     5,     1,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100]])>)\n"
     ]
    }
   ],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "tf_eval_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")\n",
    "# Example of iterating over batches\n",
    "for batch in tf_train_dataset.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f7d0f-b379-4da4-a018-4326e5f7044d",
   "metadata": {},
   "source": [
    "### Fine-tuning T5\n",
    "\n",
    "We are now ready to set up the optimizer, compile the model, and enable mixed-precision training. Here’s how to proceed:\n",
    "\n",
    "1. **Setting Up the Optimizer**:\n",
    "\n",
    "   - **Number of Training Steps**: Calculate the total number of training steps based on the dataset size, batch size, and number of epochs.\n",
    "   - **Optimizer**: Create an optimizer with a specified initial learning rate, no warmup steps, and a weight decay rate.\n",
    "   - **Compile Model**: Compile the model with the created optimizer.\n",
    "\n",
    "\n",
    "\n",
    "2. **Enable Mixed-Precision Training**:\n",
    "   - **Mixed-Precision Training**: Set the global policy to \"mixed_float16\" to enable mixed-precision training, which can improve performance and reduce memory usage by utilizing 16-bit floating-point precision where possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d771479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T20:25:03.135496Z",
     "iopub.status.busy": "2024-07-16T20:25:03.134822Z",
     "iopub.status.idle": "2024-07-16T20:25:03.152350Z",
     "shell.execute_reply": "2024-07-16T20:25:03.151307Z",
     "shell.execute_reply.started": "2024-07-16T20:25:03.135458Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_train_epochs = 10\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=5.6e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e398ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T20:25:04.903623Z",
     "iopub.status.busy": "2024-07-16T20:25:04.902745Z",
     "iopub.status.idle": "2024-07-16T21:44:50.658065Z",
     "shell.execute_reply": "2024-07-16T21:44:50.656666Z",
     "shell.execute_reply.started": "2024-07-16T20:25:04.903589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING: AutoGraph could not transform <function create_autocast_variable at 0x7f20d0f87760> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <gast.gast.Expr object at 0x7f2094713f10>\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1699/1699 [==============================] - 551s 287ms/step - loss: 1.8564 - val_loss: 1.6245\n",
      "Epoch 2/10\n",
      "1699/1699 [==============================] - 469s 276ms/step - loss: 1.6880 - val_loss: 1.5648\n",
      "Epoch 3/10\n",
      "1699/1699 [==============================] - 471s 277ms/step - loss: 1.6243 - val_loss: 1.5383\n",
      "Epoch 4/10\n",
      "1699/1699 [==============================] - 471s 277ms/step - loss: 1.5838 - val_loss: 1.5170\n",
      "Epoch 5/10\n",
      "1699/1699 [==============================] - 471s 277ms/step - loss: 1.5507 - val_loss: 1.5007\n",
      "Epoch 6/10\n",
      "1699/1699 [==============================] - 470s 277ms/step - loss: 1.5261 - val_loss: 1.4952\n",
      "Epoch 7/10\n",
      "1699/1699 [==============================] - 470s 276ms/step - loss: 1.5077 - val_loss: 1.4892\n",
      "Epoch 8/10\n",
      "1699/1699 [==============================] - 470s 277ms/step - loss: 1.4924 - val_loss: 1.4853\n",
      "Epoch 9/10\n",
      "1699/1699 [==============================] - 471s 277ms/step - loss: 1.4848 - val_loss: 1.4843\n",
      "Epoch 10/10\n",
      "1699/1699 [==============================] - 471s 277ms/step - loss: 1.4761 - val_loss: 1.4828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f20c8172e90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    tf_train_dataset, validation_data=tf_eval_dataset ,verbose=True, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa4775-72e0-486c-81ee-9e30c58f51c9",
   "metadata": {},
   "source": [
    "## Saving and loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44112f-c69c-4587-8e6e-ff5a8feb02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"t5small\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105d6f21-ef17-48bd-9ea1-dbb7b6803d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at model/t5small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"model/t5small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea054fb-06b6-4a7b-a61a-ecd4702219c4",
   "metadata": {},
   "source": [
    "### Generating Outputs and Evaluating ROUGE Metrics\n",
    "\n",
    "After training our model, we want to evaluate its performance using ROUGE metrics. To do this, we'll generate outputs from the model and convert them to strings for comparison. We can optimize this process using TensorFlow’s XLA (Accelerated Linear Algebra) compiler for improved speed and memory usage.\n",
    "\n",
    "Here's how to set up and use XLA for generating predictions:\n",
    "\n",
    "1. **Setting Up Data Collator and Dataset**:\n",
    "   - **Data Collator**: Pad inputs to multiples of 320 for consistent input shapes, which is beneficial for XLA optimization.\n",
    "   - **Dataset Preparation**: Prepare the validation dataset with the generation data collator.\n",
    "\n",
    "2. **Generating Outputs with XLA**:\n",
    "   - **XLA Compilation**: Apply the `@tf.function(jit_compile=True)` decorator to mark the generation function for XLA compilation.\n",
    "\n",
    "3. **Collecting Predictions and Labels**:\n",
    "   - **Loop through Dataset**: Generate predictions for each batch, decode the predictions and labels, and store them for ROUGE evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42caccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/289 [00:00<?, ?it/s]W0000 00:00:1721168721.853366  177292 assert_op.cc:38] Ignoring Assert operator encoder/assert_less/Assert/Assert\n",
      "W0000 00:00:1721168721.933658  177292 assert_op.cc:38] Ignoring Assert operator tft5_for_conditional_generation_1/decoder/assert_less/Assert/Assert\n",
      "W0000 00:00:1721168722.110381  177292 assert_op.cc:38] Ignoring Assert operator while/tft5_for_conditional_generation_1/decoder/assert_less/Assert/Assert\n",
      "  0%|▏                                          | 1/289 [00:04<21:11,  4.41s/it]W0000 00:00:1721168726.400773  177292 assert_op.cc:38] Ignoring Assert operator encoder/assert_less/Assert/Assert\n",
      "W0000 00:00:1721168726.494179  177292 assert_op.cc:38] Ignoring Assert operator tft5_for_conditional_generation_1/decoder/assert_less/Assert/Assert\n",
      "W0000 00:00:1721168726.687617  177292 assert_op.cc:38] Ignoring Assert operator while/tft5_for_conditional_generation_1/decoder/assert_less/Assert/Assert\n",
      "100%|████████████████████████████████████████▊| 288/289 [00:34<00:00, 10.88it/s]2024-07-17 01:55:54.964230: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|█████████████████████████████████████████| 289/289 [00:34<00:00,  8.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "generation_data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=320\n",
    ")\n",
    "\n",
    "tf_generate_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    collate_fn=generation_data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    drop_remainder=True,\n",
    ")\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def generate_with_xla(batch):\n",
    "    return model.generate(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "        max_new_tokens=32,\n",
    "    )\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for batch, labels in tqdm(tf_generate_dataset):\n",
    "    predictions = generate_with_xla(batch)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    all_preds.extend(decoded_preds)\n",
    "    all_labels.extend(decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afd1ad-517b-403a-8331-6727f67f7f14",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc7b7209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 42.7166, 'rouge2': 15.7808, 'rougeL': 33.6738, 'rougeLsum': 37.8919}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rouge_score.compute(\n",
    "    predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    ")\n",
    "result = {key: value * 100 for key, value in result.items()}\n",
    "{k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c79a11-d758-4cc5-8164-d6bdc3fb79a7",
   "metadata": {},
   "source": [
    "### Using Fine-tuned Model\n",
    "\n",
    "Once we've fine-tuned the model, we can use it for inference. \n",
    "\n",
    "- **Pipeline Object**: The `pipeline` function simplifies the process of using the model for a specific task, such as summarization. By specifying `\"summarization\"` and providing the fine-tuned model, you create an easy-to-use summarizer.\n",
    "- **Inference**: The `summarizer` can then be used to generate summaries for any input text, making it convenient to leverage the fine-tuned model for real-world applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fef629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eda560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(idx):\n",
    "    review = english_dataset[\"test\"][idx][\"dialogue\"]\n",
    "    title = english_dataset[\"test\"][idx][\"summary\"]\n",
    "    summary = summarizer(english_dataset[\"test\"][idx][\"dialogue\"])[0][\"summary_text\"]\n",
    "    print(f\"'>>> Review: {review}'\")\n",
    "    print(f\"\\n'>>> Title: {title}'\")\n",
    "    print(f\"\\n'>>> Summary: {summary}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d430e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review: Josh: Stephen, I think you've accidentaly taken my notebook home\n",
      "Stephen: wait lemme check\n",
      "Stephen: nope, I don't see it anywhere\n",
      "Jack: oh shit, I've got it xDDD I don't even know why\n",
      "Josh: xDDD ok, no problem, cool I know where it is\n",
      "Jack: I'll bring it tomorow'\n",
      "\n",
      "'>>> Title: Josh thinks Stephen accidentally took his notebook. Jack has it and will bring it tomorrow.'\n",
      "\n",
      "'>>> Summary: Stephen accidentally took his notebook home. Jack will bring it tomorow, but he doesn't know where it's and he's not sure why.'\n"
     ]
    }
   ],
   "source": [
    "print_summary(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb65f8-ffbd-4e94-b522-9a59e33aee06",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f3c9971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 186. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"a witness saw Tom Evans near the jewelry store that night. Detective Miller helps him to tell the full story, but he doesn't know what to do.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = \"\"\"\n",
    "Detective Miller: \"Mr. Evans, do you know why you're here?\"\n",
    "\n",
    "Tom Evans: \"I already told you, I don't know anything about the robbery. I was at home.\"\n",
    "\n",
    "Detective Miller: \"A witness saw you near the jewelry store that night.\"\n",
    "\n",
    "Tom Evans: \"That's impossible! I was home.\"\n",
    "\n",
    "Detective Miller: (showing a photo) \"This blurry image matches your tattoo.\"\n",
    "\n",
    "Tom Evans: \"Fine, I was there. But I didn’t do anything. I was just watching.\"\n",
    "\n",
    "Detective Miller: \"Watching? You need to tell the full story.\"\n",
    "\n",
    "Tom Evans: \"Alright, but I need protection. Those guys don’t play around.\"\n",
    "\n",
    "Detective Miller: \"You help us, we help you. Start talking.\"\n",
    "\n",
    "Tom Evans: \"Okay... it started a few weeks ago...\"\n",
    "\"\"\"\n",
    "\n",
    "summarizer(dialogue)[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efe0b4-6b1e-45d1-ae49-1ecbfd6b484e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
