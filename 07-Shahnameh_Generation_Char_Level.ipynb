{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shahnameh Character-Level Text Generation\n",
    "\n",
    "This project focuses on building a text generation model inspired by the Shahnameh, an epic poem by the Persian poet Ferdowsi. Using natural language processing (NLP) techniques, the model generates text at the character level, aiming to capture the intricate nuances of the original work's language. Trained on the extensive corpus of the Shahnameh, the model learns the intricate patterns and stylistic elements inherent in the characters, thereby producing text that echoes the rich and evocative nature of the epic poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cRLmp3TmUF53"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '20'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import GRU, Dropout, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QomY8zJwSS07"
   },
   "outputs": [],
   "source": [
    "path = 'archive/shahname_fa.txt'\n",
    "def read_text(path):\n",
    "  with open(path, 'rb') as file:\n",
    "    return file.read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "dPLo_rNgSh5O",
    "outputId": "09dd010b-75d6-481f-a33f-f67eeab5a22c"
   },
   "outputs": [],
   "source": [
    "text = read_text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZpA1TwqTCEC",
    "outputId": "17f61fc5-6dbf-4085-eb75-01d57a3cebcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|به نام خداوند جان و خرد\n",
      "|کزین برتر اندیشه برنگذرد\n",
      "|خداوند نام و خداوند جای\n",
      "|خداوند روزی ده رهنمای\n",
      "|خداوند کیوان و گردان سپهر\n",
      "|فروزنده ماه و ناهید و مهر\n",
      "|ز نام و نشان و گمان برترست\n",
      "|نگارندهٔ بر شده پی\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvuFfwenTb66",
    "outputId": "61338fd5-d87f-4ed7-e1e5-9235fad391b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653849\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing: \n",
    "\n",
    "- Remove `\\u200c` Characters: The tf.strings.regex_replace function replaces all instances of the character `\\u200c` with an empty string, effectively removing them from the text.\n",
    "\n",
    "- Convert to String: The resulting TensorFlow string is converted back to a standard Python string using numpy().decode('utf-8').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_text = tf.strings.regex_replace(text, '\\u200c', '')\n",
    "text = stripped_text.numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Unique Characters\n",
    "\n",
    "This code snippet identifies and counts the unique characters in the text.\n",
    "\n",
    "This helps in understanding the character set for a character-level text generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Hz4BI22gVAcq"
   },
   "outputs": [],
   "source": [
    "vocabulary = sorted(set(text))\n",
    "num_unique_char = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9hUHU08WxLa",
    "outputId": "1427ec1d-0a63-4672-831e-c152c9030fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '(', ')', '|', '«', '»', '،', '؟', 'ء', 'آ', 'أ', 'ؤ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ٔ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی']\n",
      "len = 47\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)\n",
    "print(f'len = {num_unique_char}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character-Index Mapping\n",
    "\n",
    "This code creates mappings between characters and indices:\n",
    "\n",
    "1. **Character to Index**: `char_to_ids` maps characters to indices.\n",
    "2. **Index to Character**: `ids_to_char` maps indices back to characters.\n",
    "\n",
    "These mappings facilitate conversion between characters and indices for model training and text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FnFdolKUTzIq"
   },
   "outputs": [],
   "source": [
    "ids_to_char = keras.layers.StringLookup(vocabulary=vocabulary, invert=True, mask_token=None)\n",
    "char_to_ids = keras.layers.StringLookup(vocabulary=vocabulary, invert=False, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " '\\n',\n",
       " ' ',\n",
       " '(',\n",
       " ')',\n",
       " '|',\n",
       " '«',\n",
       " '»',\n",
       " '،',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ids.get_vocabulary()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting IDs to Text\n",
    "\n",
    "This function converts a sequence of character IDs back to text:\n",
    "\n",
    "1. **Map IDs to Characters**: `ids_to_char(ids).numpy()` returns characters.\n",
    "2. **Decode Characters**: `[char.decode('utf-8') for char in characters]`.\n",
    "3. **Join Characters**: `''.join(decoded_characters)`.\n",
    "\n",
    "The function returns the decoded text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_eFvfnaQUf3e"
   },
   "outputs": [],
   "source": [
    "def ids_to_text(ids):\n",
    "  characters = ids_to_char(ids).numpy()\n",
    "  decoded_characters = [char.decode('utf-8') for char in characters]\n",
    "  decoded_characters_str = ''.join(decoded_characters)\n",
    "  return decoded_characters_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "_r9LIIWlY5mN",
    "outputId": "e99fd906-37bb-4e1d-e9f0-49c26fd76869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'خوب'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [21, 40, 16]\n",
    "ids_to_text(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Text to IDs\n",
    "\n",
    "This line converts a text string into a sequence of character IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmnGzmg4Z0_3",
    "outputId": "2ce22a52-ffa3-439b-8e98-ea9ce7a7350b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2647386,), dtype=int64, numpy=array([ 5, 16, 39, ..., 47, 38,  1])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_ids = char_to_ids(list(text))\n",
    "text_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training Sequences\n",
    "\n",
    "This code segment prepares the text data for training by creating sequences of character IDs:\n",
    "\n",
    "1. **Create Dataset**: `tf.data.Dataset.from_tensor_slices(text_to_ids)` creates a dataset directly from the character IDs derived from the text.\n",
    "\n",
    "2. **Batching Sequences**: `seq.batch(MAX_SEQ + 1, drop_remainder=True)` batches the sequences, each containing `MAX_SEQ + 1` characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GtQqcal6bZWP"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ = 100\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "seq = tf.data.Dataset.from_tensor_slices(text_to_ids)\n",
    "dataset = seq.batch(MAX_SEQ + 1, num_parallel_calls=AUTOTUNE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMAC6v8qcnBX",
    "outputId": "8fcea2f9-93e4-4b21-ac44-f122e5e54c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|به نام خداوند جان و خرد\n",
      "|کزین برتر اندیشه برنگذرد\n",
      "|خداوند نام و خداوند جای\n",
      "|خداوند روزی ده رهنمای\n",
      "|خ\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "  print(ids_to_text(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Input and Target Sequences\n",
    "\n",
    "This function generates input and target sequences for training:\n",
    "\n",
    "- **Inputs**: `ids[:-1]` extracts all characters except the last one, serving as the input sequence.\n",
    "- **Target**: `ids[1:]` extracts all characters except the first one, serving as the target sequence.\n",
    "\n",
    "This function prepares the data for training the text generation model by pairing input and target sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dtwClmhSctse"
   },
   "outputs": [],
   "source": [
    "def create_input_target(ids):\n",
    "  inputs = ids[:-1]\n",
    "  target = ids[1:]\n",
    "  return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vJf94h6RdGBz"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(create_input_target, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWc2S8qFdMtZ",
    "outputId": "32e2cafb-0736-4ef4-9de8-e6b4bf7920bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|به نام خداوند جان و خرد\n",
      "|کزین برتر اندیشه برنگذرد\n",
      "|خداوند نام و خداوند جای\n",
      "|خداوند روزی ده رهنمای\n",
      "|\n",
      "******\n",
      "به نام خداوند جان و خرد\n",
      "|کزین برتر اندیشه برنگذرد\n",
      "|خداوند نام و خداوند جای\n",
      "|خداوند روزی ده رهنمای\n",
      "|خ\n"
     ]
    }
   ],
   "source": [
    "for i, o in dataset.take(1):\n",
    "    print(ids_to_text(i))\n",
    "    print('******')\n",
    "    print(ids_to_text(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training batches\n",
    "\n",
    "After segmenting the text into manageable sequences, the next step is to prepare the data for model training. This involves two main steps: shuffling the data and packing it into batches.\n",
    "\n",
    "Shuffling ensures that the model encounters a diverse range of examples during training, preventing it from learning any sequential patterns. Batching groups these sequences together, making training more efficient by processing multiple examples at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UTv5T8wAdhUT"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE, drop_remainder=True)\n",
    "dataset = dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoB4-vFSe-fC",
    "outputId": "32392250-39ef-44ec-fc47-fa5d42badbc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100) (64, 100)\n"
     ]
    }
   ],
   "source": [
    "for i, o in dataset.take(1):\n",
    "  print(i.shape, o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The **MyModel** class is a custom TensorFlow/Keras model for text generation. It comprises three main layers:\n",
    "\n",
    "- **Embedding Layer:** Maps input token indices to dense embedding vectors.\n",
    "- **GRU Layer:** Processes the embedded sequences, producing output sequences and new states.\n",
    "- **Dense Layer:** Converts GRU output sequences to logits over the vocabulary.\n",
    "\n",
    "The `call` method defines the forward pass of the model, taking input sequences and optionally initial states, and returning output logits and new states if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6pXTSXwlfAiN"
   },
   "outputs": [],
   "source": [
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, vocab_size, embd_dim, rnn_units):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.embedding = Embedding(vocab_size, embd_dim)\n",
    "        self.gru = GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        \n",
    "        x = self.embedding(inputs)\n",
    "        \n",
    "        if states == None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "            \n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x)\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcB678z2hpqH",
    "outputId": "edf284a1-44fb-4eca-b639-397c862516d6"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(char_to_ids.get_vocabulary())\n",
    "EMBD_DIM = 512\n",
    "RNN_UNITS = 1048\n",
    "model = MyModel(VOCAB_SIZE, EMBD_DIM, RNN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 48)\n"
     ]
    }
   ],
   "source": [
    "for input_ids, target_ids in dataset.take(1):\n",
    "    pred = model(input_ids)\n",
    "    print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  24576     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  4910928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  50352     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4985856 (19.02 MB)\n",
      "Trainable params: 4985856 (19.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MGphYtmEip5m"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzRVWzYMjUaw",
    "outputId": "7ca0eef7-433a-4926-e921-5dc25c51bd51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 2.0606\n",
      "Epoch 2/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.4680\n",
      "Epoch 3/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.3205\n",
      "Epoch 4/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.2463\n",
      "Epoch 5/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.1920\n",
      "Epoch 6/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.1446\n",
      "Epoch 7/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.0996\n",
      "Epoch 8/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.0555\n",
      "Epoch 9/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 1.0119\n",
      "Epoch 10/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9731\n",
      "Epoch 11/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9423\n",
      "Epoch 12/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9276\n",
      "Epoch 13/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9210\n",
      "Epoch 14/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9145\n",
      "Epoch 15/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9102\n",
      "Epoch 16/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9090\n",
      "Epoch 17/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9048\n",
      "Epoch 18/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9025\n",
      "Epoch 19/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9071\n",
      "Epoch 20/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9033\n",
      "Epoch 21/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9065\n",
      "Epoch 22/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9096\n",
      "Epoch 23/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9083\n",
      "Epoch 24/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9151\n",
      "Epoch 25/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9172\n",
      "Epoch 26/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9179\n",
      "Epoch 27/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9278\n",
      "Epoch 28/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9379\n",
      "Epoch 29/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9374\n",
      "Epoch 30/30\n",
      "409/409 [==============================] - 11s 26ms/step - loss: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x781f01769950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "Generating text with a character-level model involves iterating through a loop to predict the next character based on the preceding characters.\n",
    "\n",
    "It starts with an `initial text`, an initial sequence of characters. This initial text is fed into the model, which then predicts the subsequent character. The predicted character is appended to the initial text, and the process repeats. Each iteration adds one character to the generated text, gradually forming a coherent sequence. This iterative approach continues until the desired length of text is generated or until a stopping condition is met. By predicting characters based on context, the model learns to produce text that mirrors the style and content of the training data, resulting in coherent and meaningful passages.\n",
    "![Alt text](download(1).png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Step Char-Level Text Generation\n",
    "\n",
    "This class facilitates character-level text generation:\n",
    "\n",
    "- **Initialization**: \n",
    "  - It initializes with the main model (`model`), char-to-ID mapping (`char_to_ids`), ID-to-char mapping (`ids_to_char`), and a temperature parameter (`temperature`).\n",
    "  - A sparse mask prevents predicting `[UNK]` characters.\n",
    "\n",
    "- **Generation Method**: \n",
    "  - `generate_one_step` takes an input string and optionally internal states.\n",
    "  - Splits input into characters, converts to IDs, predicts the next character, applies temperature scaling, and adds a mask.\n",
    "  - Samples a character from the distribution and converts it back.\n",
    "  \n",
    "This class enables character-level text generation with controlled randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class One_Step(keras.models.Model):\n",
    "    def __init__(self, model, ids_to_char, char_to_ids, temperature=1.0):\n",
    "        super(One_Step, self).__init__()\n",
    "        self.model = model\n",
    "        self.ids_to_char = ids_to_char\n",
    "        self.char_to_ids = char_to_ids\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        skip_ids = self.char_to_ids(['[UNK]'])[:, None]\n",
    "        \n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(char_to_ids.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function()\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.char_to_ids(input_chars).to_tensor()\n",
    "\n",
    "        predicted, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "\n",
    "        predicted = predicted[:, -1, :]\n",
    "        predicted = predicted / self.temperature\n",
    "        predicted = predicted + self.prediction_mask\n",
    "\n",
    "        predicted_id = tf.random.categorical(predicted, num_samples=1)\n",
    "        predicted_id = tf.squeeze(predicted_id, axis=-1)\n",
    "\n",
    "        predicted_chars = self.ids_to_char(predicted_id)\n",
    "        \n",
    "        return predicted_chars, states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation Using One-Step Model\n",
    "\n",
    "This code generates text using the one-step text generation model (`one_step_model`).\n",
    "\n",
    "It starts with a starting phrase, `\"به نام خداوند\"` (In the name of God). Then, it iteratively calls the `generate_one_step` method of the model to predict the next character based on the previous characters. The generated characters are appended to the result list. After generating the desired number of characters (300 in this case), the generated text is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = One_Step(model, ids_to_char, char_to_ids, temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند دانای پند\n",
      "|نبد دست و دو روی و بگریختی\n",
      "|به گیتی جز از جنگ خسته مباد\n",
      "|جهان را به خواهش به خنجر زدیم\n",
      "|به دیوانگی نام مهدان بود\n",
      "|به یزدان پناهیم فرزند من\n",
      "|که بر بوم و بر خون از دادگر\n",
      "|درخت نبرد اندر آیین و دین\n",
      "|ز تخم مهان آفریدون بود\n",
      "|دگر آنک گفتی ز ایرانیان\n",
      "|به گرز گران بسته آیی به داد\n",
      "|بدو گفت شاهای گستهم و ماه\n",
      "|که او را تو از جادوی برفراخت\n",
      "|جهان آفرین را نیایش کنید\n",
      "|به جان تو هرگونهای تاج و تخت\n",
      "|چنین گفت ما را چنان کس ندید\n",
      "|که کس در جهان زشت ننگ آیدت\n",
      "|به خاقان بگفتار او راستی\n",
      "|ز بس نیزه و تیغ \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.5612320899963379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time \n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['به نام خدا'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(500):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
